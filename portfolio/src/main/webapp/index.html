<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Tony's Portfolio</title>
    <link rel="icon" type="image/png" href="/icons/google_icon.png">
    <link rel="stylesheet" href="style.css">
    <script src="script.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-105323938-4"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-105323938-4');
    </script>

    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-56HP3B7');</script>
    <!-- End Google Tag Manager -->
  </head>
  
  <body onload="getComments()">
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-56HP3B7"
        height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

    <div id="content">
      <!-- Header !-->
      <h1>Tony Pan's Portfolio</h1>

      <!-- Random Greetings !-->
      <p>Click here to receive my greeting:</p>
      <button onclick="addRandomGreeting()">Hello</button>
      <div id="greeting-container"></div>

      <!-- Profile pic !-->
      <p>Here is a photo of me hiking </p>
      <img src="/images/hiking_volcano.jpg" alt="Tony's hiking photo" style="width: 45%;">

      <!-- My background/intro !-->
      <h2>My Background</h2>
      <p>My name is Tony Pan. I am a <a href="https://buildyourfuture.withgoogle.com/programs/step/" target="_blank">STEP intern</a> at <a href="https://careers.google.com/" target="_blank">Google</a> in summer 2020.
          I am studying <a href="https://cse.engin.umich.edu/academics/undergraduate/computer-science-eng/" target="_blank">Computer Science</a> and Math at the University of Michigan Collge of Engineering.</p>
	  <p>I am passionate about intelligent robotics and AI. My career goal is to work at Google one day to develop cutting-edge technology that makes everyone's life better.</p>

      <!-- My projects !-->
      <h2>My Projects</h2>
      <p>Here are some of the projects that I have worked on:</p>
      <ul>
        <li><h3>InEKF Localization and Semantic Mapping on the KITTI Dataset</h3>
          <i>January 2020 – April 2020 at the University of Michigan</i>
          <p>This is our final project for the graduate level course Mobile Robotics: Methods and Algorithms. It is a state-of-the-art localization and mapping program combining Lie group and deep learning.</p>
          <p><i>Abstract:</i> Localization and mapping are the foundations for the movement of any mobile agent. The uncertainty in sensors prohibits accurate state estimation. 
              Traditional methods such as the EKF may not always converge to the optimal solution. 
              We have implemented a Left-Invariant Extended Kalman Filter that can better model the nonlinear uncertainty in robot motion and generate a more accurate trajectory. 
              Furthermore, using our trajectory, LiDAR points, images, and deep learning, we have built semantic maps that can encode more useful information for mobile robots.</p>
          <p><a href="https://github.com/tonypan2000/EECS568_final" target="_blank">Read our code</a>, <a href="https://youtu.be/A9tSE8NMWzA" target="_blank">watch our presentation</a>, <a 
              href="/files/EECS_568_Final_Report.pdf" target="_blank">read our report</a>
          </p>
        </li>

        <li><h3>AuTom and Jerry: Autonomously Detect and Approach Manually Controlled Mobile Agents</h3>
          <i>September 2019 – December 2019 at the University of Michigan</i>
          <p>This is our final project for the senior major design course Autonomous Robotics Design Experience. Our project is inspired by the "Push-button Kitty" episode of Tom and Jerry. 
              We have developed an intelligent mobile robot that can detect and capture a manually controlled moving agent. We approached this "predator-prey" project with SLAM, computer vision, and PID controller.</p>
          <p><a href="https://youtu.be/uizK_nXCeBg" target="_blank">Watch our demonstration</a>, <a href="/files/467_final_report.pdf" target="_blank">read our report</a>, <a href="/files/467_poster-compressed.pdf" 
              target="_blank">see our poster</a>
          </p>
        </li>

        <li><h3>Reducing Global Cumulative Odometry Error with Overhead Camera Localization in the Soar Cognitive Architecture</h3>
          <i>May 2019 – August 2019 at the University of Michigan</i>
          <p>This is our research project with EECS Professor <a href="https://soar.eecs.umich.edu/" target="_blank">John Laird</a>. When mobile robots rely on odometry for pose estimation, 
              they drift over time due to various sources of odometry error. 
              We have developed a method to correct the global position of the agent with ArUco markers and OpenCV.</p>
          <p>This project is based on the Cozmo-Soar interface connecting Anki's Cozmo robots with the Soar Cognitive Architecture. 
              <q>Soar is a general cognitive architecture that integrates knowledge-intensive reasoning, reactive execution, hierachical reasoning, planning, and learning from experience,
              with the goal of creating a general computatiojnal system that has the same cognitive abilities as humans.</q> The purpose of the Cozmo-Soar interface is to 
              <q>allow a Soar agent to control a fully-embodied Cozmo robot, thereby embodying the Soar agent in the real-world and enabling cognitive experiments to be run on a small, flexible, and robust platform.</q> 
              The research goal of Cozmo-Soar is interactive task learning, specifically training the Cozmo robots new tasks through natural language instruction.
          </p>
          <p><a href="https://github.com/tonypan2000/CozmoSoar" target="_blank">Read our code</a>, <a href="/files/overhead_camera_report.pdf" target="_blank">read our report</a>
          </p>
        </li>

        <li><h3>Machine Learning Assisted Blood Vessel Segmentation in Laser Speckle Imaging</h3>
          <i>July 2018 at the Weizmann Institute of Science, Israel</i>
          <p>Published in <i>Proceedings Volume 10873, Optical Biopsy XVII: Toward Real-Time Spectroscopic Imaging and Diagnosis</i> in <i>March 2019</i></p>
          <p>I gave an oral presentation at the <a href="https://spie.org/conferences-and-exhibitions/photonics-west/bios" target="_blank">
              <i>SPIE Photonics West BiOS</i></a> conference in <i>San Francisco, CA</i> in <i>February 2019</i></p>
          <p>This research project was mentored by Professor Vyacheslav Kalchenko as a part of the <a href="https://www.weizmann-usa.org/about/education/bessie-f-lawrence-international-summer-science-institute" 
              target="_blank">International Summer Science Institute</a> program.
              Our project aimed at improving an inexpensive and promising medical imaging method called laser speckle imaging with machine learning techniques. 
              Our preliminary report is <i>MAKING THE INVISIBLE VISIBLE: Optimizing Laser Speckle Imaging by using machine learning and targeted recoloring.</i>
          </p>
          <p><i>Abstract:</i> We are introducing an application of a machine learning approach for express analysis of Laser Speckle (LS) images. 
              This application can be utilized for real-time visualisation of vascular beds in vivo.
              This research used Waikato Environment for Knowledge Analysis (Weka) integrated with Fiji/ImageJ software. A large number of acquired LS images are averaged, then used as references for training Weka classifiers. 
              Subsequently, a bundle of these Weka classifiers are produced. We defined the minimal number of raw LS images based on a phenomenological model to minimize the time needed for LS data analysis. 
              Finally, a new perceptually uniform color coding approach is developed for highlighting targeted blood vessels. The developed LS processing approach is especially convenient, 
              because of its high potential for blood vessel visualisation during real-time intraoperative vascular imaging in vivo.</p>
          <p><a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10873/2510378/Machine-learning-assisted-blood-vessel-segmentation-in-laser-speckle-imaging/10.1117/12.2510378.full" 
              target="_blank">Watch our presentation</a>, <a href="/files/weizmann_paper.pdf" target="_blank">read our report</a>
          </p>
        </li>

        <li><h3>Making Scalable Inexpensive High Power and Energy Density Graphene Supercapacitors with the LightScribe Method</h3>
          <i>September 2017 - May 2018 during high school</i>
          <p>This project qualified me for the <a href="https://www.societyforscience.org/isef/" target="_blank">International Science and Engineering Fair (ISEF)</a> in Pittsburgh in 2018.</p>
          <p><i>Abstract:</i> Improvements in energy storage devices can help facilitate the implementation of renewable energy resources in collecting energy, energy storage, and using the energy efficiently. 
              Most energy storage devices today face similar problems: slow charging time, low power and energy density, safety, and cost. The goal of this research is to address these issues with graphene supercapacitors. 
              Graphene supercapacitors have fast charging and discharging rates, which not only reduce charging time but also enable better performance. 
              The improvements in the electrolytes and the pattern design can further increase graphene supercapacitors’ power and energy density.
              This research focused on scalable inexpensive graphene supercapacitors from graphite oxide exfoliated with LightScribe DVD burners. 
              It demonstrated the feasibility of an inexpensive scalable high energy density graphene supercapacitor.</p>
          <p><a href="/files/ISEF_poster.pdf" target="_blank">See my poster</a>, <a href="/files/ISEF_paper.pdf" target="_blank">read my report</a>
          </p>
        </li>
      </ul>

      <!-- Social links !-->
      <h2>Connect with me!</h2>
      <P>
        <a href="https://www.linkedin.com/in/tony-pan/" target="_blank" title="Linkedin"><img id="icon1" src="/icons/linkedin_icon.png" alt="My Linkedin"></a>
        <a href="https://github.com/tonypan2000" target="_blank" title="Github"><img id="icon2" src="/icons/github_icon.jpeg" alt="My Github"></a>
        <a href="https://www.instagram.com/tonypan2000/" target="_blank" title="Instagram"><img id="icon3" src="/icons/insta_icon.png" alt="My Instagram"></a>
        <a href="https://twitter.com/tonypan2000" target="_blank" title="Twitter"><img id="icon4" src="/icons/twitter_icon.png" alt="My Twitter"></a>
        <a href="https://www.facebook.com/tonypan2000" target="_blank" title="Facebook"><img id="icon5" src="/icons/facebook_icon.png" alt="My Facebook"></a>
        <a href="https://www.youtube.com/channel/UCp-751qVxozwSihorCI6iNw" target="_blank" title="Youtube"><img id="icon6" src="/icons/youtube_icon.png" alt="My YouTube"></a>
      </p>

      <!-- Random facts about me !-->
      <p>Click here to learn a random fun fact about me:</p>
      <button onclick="addRandomFact()">Fun Fact</button>
      <div id="fact-container"></div> 

      <!-- Form for comments !-->
      <form action="/data" method="POST" id="post-event">
        <h2>Post Your Comment!</h2>
        <label for="name">Your name:</label>
        <!-- TODO: Check for min length of entries (in Javascript) and warn user !-->
        <input type="text" id="name" name="name-input" minlength="1" />
        <br><br>
        <textarea id="comment-form" name="comment-input" minlength="1"></textarea>
        <br><br>
        <input type="submit" />
      </form>

      <!-- Displays all previously entered comments !-->
      <h2>Previous Comments</h2>
      <p>Max Number of Comments:</p>
      <input type="number" id="max-num-comments" name="max-num-comments" min="0" value="5">
      <button onclick="refreshComments()">Set</button>
      <br><br>
      <ul id="previous-comments"></ul>
    </div>
  </body>
</html>
